{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Analysis and Prediction Project\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on the stock market data collected from Yahoo Finance API. We'll analyze price trends, calculate financial metrics, and create visualizations to gain insights into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set plot styles\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Increase plot size\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define the database path\n",
    "DB_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))), 'data', 'stock_data.db')\n",
    "print(f\"Database path: {DB_PATH}\")\n",
    "\n",
    "# Function to connect to the database\n",
    "def get_connection():\n",
    "    return sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Function to get stock data from the database\n",
    "def get_stock_data(symbol=None):\n",
    "    conn = get_connection()\n",
    "    \n",
    "    if symbol:\n",
    "        query = \"\"\"\n",
    "        SELECT s.symbol, s.company_name, p.date, p.open, p.high, p.low, p.close, p.adj_close, p.volume\n",
    "        FROM stocks s\n",
    "        JOIN stock_prices p ON s.id = p.stock_id\n",
    "        WHERE s.symbol = ?\n",
    "        ORDER BY p.date\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn, params=(symbol,))\n",
    "    else:\n",
    "        query = \"\"\"\n",
    "        SELECT s.symbol, s.company_name, p.date, p.open, p.high, p.low, p.close, p.adj_close, p.volume\n",
    "        FROM stocks s\n",
    "        JOIN stock_prices p ON s.id = p.stock_id\n",
    "        ORDER BY s.symbol, p.date\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to get technical indicators from the database\n",
    "def get_technical_indicators(symbol):\n",
    "    conn = get_connection()\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT s.symbol, t.date, t.sma_20, t.sma_50, t.sma_200, t.rsi_14, t.macd, t.macd_signal,\n",
    "           t.bollinger_upper, t.bollinger_middle, t.bollinger_lower\n",
    "    FROM stocks s\n",
    "    JOIN technical_indicators t ON s.id = t.stock_id\n",
    "    WHERE s.symbol = ?\n",
    "    ORDER BY t.date\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql_query(query, conn, params=(symbol,))\n",
    "    conn.close()\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Get list of available stocks\n",
    "def get_stock_list():\n",
    "    conn = get_connection()\n",
    "    query = \"SELECT symbol, company_name FROM stocks ORDER BY symbol\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get list of available stocks\n",
    "stocks_df = get_stock_list()\n",
    "stocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of Stock Price Data\n",
    "\n",
    "Let's first look at the closing prices of all stocks over time to get a general overview of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get all stock data\n",
    "all_stocks_df = get_stock_data()\n",
    "\n",
    "# Display the first few rows\n",
    "all_stocks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "all_stocks_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot closing prices for all stocks\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Create a pivot table with dates as index and symbols as columns\n",
    "pivot_df = all_stocks_df.pivot_table(index='date', columns='symbol', values='close')\n",
    "\n",
    "# Plot each stock\n",
    "for column in pivot_df.columns:\n",
    "    plt.plot(pivot_df.index, pivot_df[column], label=column)\n",
    "\n",
    "plt.title('Stock Closing Prices Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Closing Price (USD)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/all_stocks_closing_prices.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the raw closing prices, but it's difficult to compare stocks with very different price ranges. Let's normalize the prices to see relative performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Normalize prices (percentage change from first day)\n",
    "normalized_df = pivot_df.copy()\n",
    "for column in normalized_df.columns:\n",
    "    normalized_df[column] = normalized_df[column] / normalized_df[column].iloc[0] * 100\n",
    "\n",
    "# Plot normalized prices\n",
    "plt.figure(figsize=(16, 10))\n",
    "for column in normalized_df.columns:\n",
    "    plt.plot(normalized_df.index, normalized_df[column], label=column)\n",
    "\n",
    "plt.title('Normalized Stock Performance (Base 100)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Normalized Price (%)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/normalized_stock_performance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detailed Analysis of Individual Stocks\n",
    "\n",
    "Let's analyze each stock in more detail, starting with Netflix (NFLX) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get Netflix data\n",
    "nflx_df = get_stock_data('NFLX')\n",
    "nflx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot NFLX price with volume\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, \n",
    "                    vertical_spacing=0.1, subplot_titles=('NFLX Price', 'Volume'),\n",
    "                    row_heights=[0.7, 0.3])\n",
    "\n",
    "# Add price candlestick chart\n",
    "fig.add_trace(go.Candlestick(x=nflx_df['date'],\n",
    "                            open=nflx_df['open'],\n",
    "                            high=nflx_df['high'],\n",
    "                            low=nflx_df['low'],\n",
    "                            close=nflx_df['close'],\n",
    "                            name='Price'),\n",
    "              row=1, col=1)\n",
    "\n",
    "# Add volume bar chart\n",
    "fig.add_trace(go.Bar(x=nflx_df['date'], y=nflx_df['volume'], name='Volume', marker_color='rgba(0, 0, 255, 0.5)'),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Netflix (NFLX) Stock Price and Volume',\n",
    "                  xaxis_title='Date',\n",
    "                  yaxis_title='Price (USD)',\n",
    "                  xaxis_rangeslider_visible=False,\n",
    "                  height=800,\n",
    "                  width=1200)\n",
    "\n",
    "fig.write_html('../visualizations/nflx_price_volume.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get technical indicators for NFLX\n",
    "nflx_indicators = get_technical_indicators('NFLX')\n",
    "nflx_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Merge price data with technical indicators\n",
    "nflx_merged = pd.merge(nflx_df, nflx_indicators, on=['symbol', 'date'])\n",
    "nflx_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot NFLX price with moving averages\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(nflx_merged['date'], nflx_merged['close'], label='Close Price', alpha=0.7)\n",
    "plt.plot(nflx_merged['date'], nflx_merged['sma_20'], label='20-day SMA', alpha=0.7)\n",
    "plt.plot(nflx_merged['date'], nflx_merged['sma_50'], label='50-day SMA', alpha=0.7)\n",
    "plt.plot(nflx_merged['date'], nflx_merged['sma_200'], label='200-day SMA', alpha=0.7)\n",
    "\n",
    "plt.title('Netflix (NFLX) Stock Price with Moving Averages', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Price (USD)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/nflx_moving_averages.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot NFLX with Bollinger Bands\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(nflx_merged['date'], nflx_merged['close'], label='Close Price', color='blue', alpha=0.7)\n",
    "plt.plot(nflx_merged['date'], nflx_merged['bollinger_upper'], label='Upper Band', color='red', alpha=0.5)\n",
    "plt.plot(nflx_merged['date'], nflx_merged['bollinger_middle'], label='Middle Band', color='green', alpha=0.5)\n",
    "plt.plot(nflx_merged['date'], nflx_merged['bollinger_lower'], label='Lower Band', color='red', alpha=0.5)\n",
    "\n",
    "# Fill between upper and lower bands\n",
    "plt.fill_between(nflx_merged['date'], nflx_merged['bollinger_upper'], nflx_merged['bollinger_lower'], \n",
    "                 color='gray', alpha=0.2)\n",
    "\n",
    "plt.title('Netflix (NFLX) Stock Price with Bollinger Bands', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Price (USD)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/nflx_bollinger_bands.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot RSI for NFLX\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(nflx_merged['date'], nflx_merged['rsi_14'], label='RSI-14', color='purple')\n",
    "plt.axhline(y=70, color='red', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=30, color='green', linestyle='--', alpha=0.5)\n",
    "plt.fill_between(nflx_merged['date'], nflx_merged['rsi_14'], 70, where=(nflx_merged['rsi_14'] >= 70), color='red', alpha=0.3)\n",
    "plt.fill_between(nflx_merged['date'], nflx_merged['rsi_14'], 30, where=(nflx_merged['rsi_14'] <= 30), color='green', alpha=0.3)\n",
    "\n",
    "plt.title('Netflix (NFLX) Relative Strength Index (RSI-14)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('RSI Value', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/nflx_rsi.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot MACD for NFLX\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(nflx_merged['date'], nflx_merged['macd'], label='MACD', color='blue')\n",
    "plt.plot(nflx_merged['date'], nflx_merged['macd_signal'], label='Signal Line', color='red')\n",
    "plt.bar(nflx_merged['date'], nflx_merged['macd'] - nflx_merged['macd_signal'], \n",
    "        label='Histogram', color=['green' if val >= 0 else 'red' for val in (nflx_merged['macd'] - nflx_merged['macd_signal'])], alpha=0.5)\n",
    "\n",
    "plt.title('Netflix (NFLX) MACD Indicator', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('MACD Value', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/nflx_macd.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparative Analysis of Tech Stocks\n",
    "\n",
    "Let's compare the performance of tech stocks in our dataset (AAPL, AMZN, GOOGL, META, MSFT, NFLX, TSLA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for tech stocks\n",
    "tech_stocks = ['AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NFLX', 'TSLA']\n",
    "tech_df = all_stocks_df[all_stocks_df['symbol'].isin(tech_stocks)]\n",
    "\n",
    "# Create a pivot table with dates as index and symbols as columns\n",
    "tech_pivot = tech_df.pivot_table(index='date', columns='symbol', values='close')\n",
    "\n",
    "# Normalize prices (percentage change from first day)\n",
    "tech_normalized = tech_pivot.copy()\n",
    "for column in tech_normalized.columns:\n",
    "    tech_normalized[column] = tech_normalized[column] / tech_normalized[column].iloc[0] * 100\n",
    "\n",
    "# Plot normalized prices\n",
    "plt.figure(figsize=(16, 10))\n",
    "for column in tech_normalized.columns:\n",
    "    plt.plot(tech_normalized.index, tech_normalized[column], label=column)\n",
    "\n",
    "plt.title('Normalized Tech Stock Performance (Base 100)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Normalized Price (%)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/tech_stocks_normalized.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate daily returns\n",
    "tech_returns = tech_pivot.pct_change().dropna()\n",
    "\n",
    "# Plot correlation heatmap of daily returns\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = tech_returns.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
    "plt.title('Correlation of Daily Returns Among Tech Stocks', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/tech_stocks_correlation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate volatility (standard deviation of returns)\n",
    "volatility = tech_returns.std() * np.sqrt(252)  # Annualized volatility\n",
    "\n",
    "# Calculate average annual return\n",
    "annual_return = tech_returns.mean() * 252  # Annualized return\n",
    "\n",
    "# Create a DataFrame for risk-return analysis\n",
    "risk_return = pd.DataFrame({\n",
    "    'Volatility (Risk)': volatility,\n",
    "    'Annual Return': annual_return\n",
    "})\n",
    "\n",
    "# Plot risk-return scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(risk_return['Volatility (Risk)'], risk_return['Annual Return'], s=100)\n",
    "\n",
    "# Add labels for each stock\n",
    "for i, stock in enumerate(risk_return.index):\n",
    "    plt.annotate(stock, \n",
    "                 (risk_return['Volatility (Risk)'][i], risk_return['Annual Return'][i]),\n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=12)\n",
    "\n",
    "plt.title('Risk-Return Profile of Tech Stocks', fontsize=16)\n",
    "plt.xlabel('Volatility (Risk)', fontsize=14)\n",
    "plt.ylabel('Annual Return', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/tech_stocks_risk_return.png')\n",
    "plt.show()\n",
    "\n",
    "# Display the risk-return data\n",
    "risk_return.sort_values('Annual Return', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sector Analysis\n",
    "\n",
    "Let's group stocks by sector and analyze sector performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get sector information\n",
    "conn = get_connection()\n",
    "sector_query = \"SELECT symbol, sector FROM stocks\"\n",
    "sector_df = pd.read_sql_query(sector_query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Display sectors\n",
    "sector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Group stocks by sector\n",
    "sectors = {}\n",
    "for sector in sector_df['sector'].unique():\n",
    "    sectors[sector] = sector_df[sector_df['sector'] == sector]['symbol'].tolist()\n",
    "\n",
    "# Create a DataFrame with sector average performance\n",
    "sector_performance = pd.DataFrame(index=pivot_df.index)\n",
    "\n",
    "for sector, symbols in sectors.items():\n",
    "    # Filter pivot_df for symbols in this sector\n",
    "    sector_stocks = pivot_df[symbols]\n",
    "    \n",
    "    # Normalize each stock\n",
    "    normalized_sector = sector_stocks.copy()\n",
    "    for column in normalized_sector.columns:\n",
    "        normalized_sector[column] = normalized_sector[column] / normalized_sector[column].iloc[0] * 100\n",
    "    \n",
    "    # Calculate sector average\n",
    "    sector_performance[sector] = normalized_sector.mean(axis=1)\n",
    "\n",
    "# Plot sector performance\n",
    "plt.figure(figsize=(16, 10))\n",
    "for column in sector_performance.columns:\n",
    "    plt.plot(sector_performance.index, sector_performance[column], label=column, linewidth=2)\n",
    "\n",
    "plt.title('Normalized Sector Performance (Base 100)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Normalized Price (%)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/sector_performance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Volume Analysis\n",
    "\n",
    "Let's analyze trading volume patterns across stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a pivot table for volume\n",
    "volume_pivot = all_stocks_df.pivot_table(index='date', columns='symbol', values='volume')\n",
    "\n",
    "# Calculate average daily volume for each stock\n",
    "avg_volume = volume_pivot.mean()\n",
    "avg_volume_df = pd.DataFrame({'Average Daily Volume': avg_volume}).sort_values('Average Daily Volume', ascending=False)\n",
    "\n",
    "# Plot average daily volume\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(avg_volume_df.index, avg_volume_df['Average Daily Volume'], color='skyblue')\n",
    "plt.title('Average Daily Trading Volume by Stock', fontsize=16)\n",
    "plt.xlabel('Stock Symbol', fontsize=14)\n",
    "plt.ylabel('Average Volume (Shares)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/average_daily_volume.png')\n",
    "plt.show()\n",
    "\n",
    "# Display the average volume data\n",
    "avg_volume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot volume trends over time for top 5 stocks by volume\n",
    "top_volume_stocks = avg_volume_df.head(5).index.tolist()\n",
    "volume_subset = volume_pivot[top_volume_stocks]\n",
    "\n",
    "# Resample to monthly for clearer visualization\n",
    "monthly_volume = volume_subset.resample('M', on=volume_subset.index).mean()\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "for column in monthly_volume.columns:\n",
    "    plt.plot(monthly_volume.index, monthly_volume[column], label=column, linewidth=2)\n",
    "\n",
    "plt.title('Monthly Average Trading Volume for Top 5 Stocks', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Volume (Shares)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/monthly_volume_trends.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Volatility Analysis\n",
    "\n",
    "Let's analyze the volatility of each stock over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate daily returns for all stocks\n",
    "returns = pivot_df.pct_change().dropna()\n",
    "\n",
    "# Calculate 30-day rolling volatility (annualized)\n",
    "volatility_30d = returns.rolling(window=30).std() * np.sqrt(252)\n",
    "\n",
    "# Plot 30-day rolling volatility for all stocks\n",
    "plt.figure(figsize=(16, 10))\n",
    "for column in volatility_30d.columns:\n",
    "    plt.plot(volatility_30d.index, volatility_30d[column], label=column)\n",
    "\n",
    "plt.title('30-Day Rolling Volatility (Annualized)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Volatility', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/rolling_volatility.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate average volatility for each stock\n",
    "avg_volatility = volatility_30d.mean().sort_values(ascending=False)\n",
    "avg_volatility_df = pd.DataFrame({'Average Volatility': avg_volatility})\n",
    "\n",
    "# Plot average volatility\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(avg_volatility_df.index, avg_volatility_df['Average Volatility'], color='salmon')\n",
    "plt.title('Average Volatility by Stock', fontsize=16)\n",
    "plt.xlabel('Stock Symbol', fontsize=14)\n",
    "plt.ylabel('Average Volatility', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/average_volatility.png')\n",
    "plt.show()\n",
    "\n",
    "# Display the average volatility data\n",
    "avg_volatility_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Seasonal Analysis\n",
    "\n",
    "Let's analyze seasonal patterns in stock returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add month and year columns to returns DataFrame\n",
    "returns_with_date = returns.copy()\n",
    "returns_with_date['month'] = returns_with_date.index.month\n",
    "returns_with_date['year'] = returns_with_date.index.year\n",
    "\n",
    "# Calculate average monthly returns for each stock\n",
    "monthly_returns = {}\n",
    "for symbol in returns.columns:\n",
    "    monthly_avg = returns_with_date.groupby('month')[symbol].mean() * 100  # Convert to percentage\n",
    "    monthly_returns[symbol] = monthly_avg\n",
    "\n",
    "# Convert to DataFrame\n",
    "monthly_returns_df = pd.DataFrame(monthly_returns)\n",
    "monthly_returns_df.index = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Plot heatmap of monthly returns\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(monthly_returns_df, annot=True, cmap='RdYlGn', center=0, fmt='.2f')\n",
    "plt.title('Average Monthly Returns by Stock (%)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/monthly_returns_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate average market return (equal-weighted portfolio)\n",
    "returns_with_date['Market'] = returns.mean(axis=1)\n",
    "market_monthly_avg = returns_with_date.groupby('month')['Market'].mean() * 100  # Convert to percentage\n",
    "market_monthly_avg.index = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Plot average market monthly returns\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = ['green' if x >= 0 else 'red' for x in market_monthly_avg]\n",
    "plt.bar(market_monthly_avg.index, market_monthly_avg, color=colors)\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.title('Average Market Monthly Returns (%)', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.ylabel('Average Return (%)', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/market_monthly_returns.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of Findings\n",
    "\n",
    "Based on our exploratory data analysis, here are the key findings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Overall Performance**: \n",
    "   - Tech stocks generally outperformed other sectors during the analyzed period.\n",
    "   - [Stock with highest return] showed the best performance with a [X]% increase.\n",
    "   - [Stock with lowest return] had the weakest performance with a [Y]% change.\n",
    "\n",
    "2. **Volatility**:\n",
    "   - [Most volatile stock] exhibited the highest volatility.\n",
    "   - [Least volatile stock] was the most stable stock in our dataset.\n",
    "   - Market volatility peaked during [specific periods], likely due to [potential reasons].\n",
    "\n",
    "3. **Correlations**:\n",
    "   - Stocks within the same sector showed stronger correlations.\n",
    "   - [Specific stocks] showed unusually high correlation despite being in different sectors.\n",
    "   - [Specific stocks] showed low correlation with the rest of the market, suggesting potential diversification benefits.\n",
    "\n",
    "4. **Seasonal Patterns**:\n",
    "   - [Specific months] typically showed stronger returns across most stocks.\n",
    "   - [Specific months] were generally weaker for stock performance.\n",
    "   - [Specific stock] showed unique seasonal patterns compared to the broader market.\n",
    "\n",
    "5. **Trading Volume**:\n",
    "   - [Specific stock] consistently had the highest trading volume.\n",
    "   - Volume spikes were observed during [specific events or periods].\n",
    "   - There appears to be a [positive/negative/no] relationship between volume and price movements.\n",
    "\n",
    "6. **Technical Indicators**:\n",
    "   - Moving averages identified key support and resistance levels for [specific stocks].\n",
    "   - RSI indicated overbought conditions for [specific stocks] during [specific periods].\n",
    "   - MACD crossovers provided potential trading signals that aligned with major price movements.\n",
    "\n",
    "These findings provide valuable insights for developing predictive models in the next phase of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on our exploratory data analysis, we'll proceed with the following steps:\n",
    "\n",
    "1. **Feature Engineering**: Create additional features based on the insights gained from this analysis.\n",
    "2. **Model Development**: Build predictive models for stock price forecasting.\n",
    "3. **Risk Analysis**: Develop a risk assessment framework based on volatility and correlation analysis.\n",
    "4. **Portfolio Optimization**: Create an optimal portfolio allocation strategy based on risk-return profiles.\n",
    "5. **Interactive Dashboard**: Develop a Power BI dashboard to visualize the findings and predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
